
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../Li2023/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.10">
    
    
      
        <title>Reconciling modern machine learning practice and the bias-variance trade-oï¬€ - Paper Summary</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.4af4bdda.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#reconciling-modern-machine-learning-practice-and-the-bias-variance-trade-off" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Paper Summary" class="md-header__button md-logo" aria-label="Paper Summary" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Paper Summary
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Reconciling modern machine learning practice and the bias-variance trade-oï¬€
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Paper Summary" class="md-nav__button md-logo" aria-label="Paper Summary" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Paper Summary
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ðŸ“š Paper Summaries
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Reconciling modern machine learning practice and the bias-variance trade-oï¬€
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Reconciling modern machine learning practice and the bias-variance trade-oï¬€
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Neural networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Neural networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#random-fourier-features" class="md-nav__link">
    <span class="md-ellipsis">
      Random Fourier features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-newtorks-and-backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      Neural newtorks and backpropagation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decision-trees-and-ensemble-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Decision trees and ensemble methods
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concluding-thoughts" class="md-nav__link">
    <span class="md-ellipsis">
      Concluding thoughts
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Li2023/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Trustworthy AI: From Principles to Practices
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Neural networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Neural networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#random-fourier-features" class="md-nav__link">
    <span class="md-ellipsis">
      Random Fourier features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-newtorks-and-backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      Neural newtorks and backpropagation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decision-trees-and-ensemble-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Decision trees and ensemble methods
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concluding-thoughts" class="md-nav__link">
    <span class="md-ellipsis">
      Concluding thoughts
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="reconciling-modern-machine-learning-practice-and-the-bias-variance-trade-off">Reconciling modern machine learning practice and the bias-variance trade-oï¬€<a class="headerlink" href="#reconciling-modern-machine-learning-practice-and-the-bias-variance-trade-off" title="Permanent link">&para;</a></h1>
<p>I am reading this paper to see how bias-variance tradeoff I learned in CS376 can be applied to DNN, which has different properties compared to classical models.</p>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>Machine learning on the problem of prediction does the following:
given training examples from $\mathbb{R}^d \times \mathbb{R}$, we learn predictor $h_n: \mathbb{R}^d \rightarrow \mathbb{R}$ by choosing from some function class $\mathcal{H}$, which is neural network with certain architecture, by minimizing empirical risk $\frac{1}{n} \sum_{i=1}^{n} \ell(h(x_i), y_i)$</p>
<p>The challenge here is mismatch between minimzaing empirical risk and minimizing true (or test) risk $\mathbb{E}_{(x,y)~P}[l(h(x), y)]$. Conventional wisdom in mathince learning controls the capacity of $\mathcal{H}$ based on bias-variance tradeoff by finding the "sweet spot" between underfitting and overfitting. Control of function class can be explicit by choice of $\mathcal{H}$, or be implicit using regularization. The performance of the model shows U-shaped risk curve.</p>
<p>But in modern mathince learning, large neural networks with hight function class capacity and near-perfect fit to training data often give very accurate predictions on new data. Recent empirical evidence indicates taht neural networks and kernel mathinces trained to interpolate the training data obtain near optimal test results even when the training data are corrupted with high levels of noise.</p>
<p>The main finding of this paper is a pattern, "double descent" risk curve, which is pattern of how performance on unseen data depends on model capacity, and the meahcanism underlying its emergence. When funtion class capacity is below interpolation threshold, learend predictors exhibit the classical U-shaped curve. But increasing the function class capacity beyond interpolation threshold leads to decreasing risk, typically going below the risk achieved at the sweet point in classical regime. Learned predictors on the right of the interpolation threshold fit the training data perfectly and have zero empirical risk, but those frome richer function classes tends to smaller norm and are thus simpler. </p>
<h2 id="neural-networks">Neural networks<a class="headerlink" href="#neural-networks" title="Permanent link">&para;</a></h2>
<h3 id="random-fourier-features">Random Fourier features<a class="headerlink" href="#random-fourier-features" title="Permanent link">&para;</a></h3>
<p>The paper first consider popular class of nonlinear parametric models called Random Fourier Features (RFF). It can be vieewd as a class of two layer neural networks with fixed weights in the first layer. RFF model family $\mathcal{H}<em>N$ with $N$ parameters consists of fucntion $h: \mathbb{R}^2 -&gt; \mathbb{C}$ of the form
$$
h(x) = \sum</em>{k=1}^{N} a_k \, \phi(x; v_k) \quad \text{where} \quad \phi(x; v) := e^{\sqrt{-1} \langle v, x \rangle},
$$
and $v_1, \dots , v_N$ are sampled independently from normal distribution. We consider $\mathcal{H}_N$ as class of real valued function as class of real valued function with $2N$ real valued parameters (real and imaginary). </p>
<p>(As $N\rightarrow \infty$, $\mathcal{H}<em>N$ becomes close aproximation to Reproducing Kernel Hilbert Space (RKHS) corresponding to gaussian kernel, denoted by $\mathcal{H}</em>{\infty}$.)</p>
<p>Given $n$ datas from $\mathbb{R}^d \times \mathbb{R}$, they find $h_{n, N} \in \mathcal{H}_N$ by ERM with squared loss. But minimizer is not unique for $N &gt; n$. In that case, they choose minimizer with the minimum $L_2$ loss coefficients. </p>
<p>When $n &lt; N$, we can observe classical U-shaped curve that can be predicted by bias variance tradeoff. for $n&gt;N$, where all function classes are rich enough to achieve zero training risk, increasing N progressively construct better approximation, showing the second descent segment of the curve. </p>
<p>There are more experiments with other dataset and models structure in appendix.</p>
<h3 id="neural-newtorks-and-backpropagation">Neural newtorks and backpropagation<a class="headerlink" href="#neural-newtorks-and-backpropagation" title="Permanent link">&para;</a></h3>
<p>In general multilayer neural networks, we use stochastic gradient descent (SGD) to fit the trainin data. They observed that increasing the number of parameters in fully connected two layer neural networks lead to a risk curve qualitatively similar to that observed with RFF models. </p>
<p>The compuational complexity of ERM with neural networks make double descent risk curve difficult to observe. In under parametrized regime, the result is highly sensitive to initialization due to nonconvexity of the ERM optimization. This variability in training and test risks masks the double descent curve. </p>
<p>To have this effect for datasets as large as ImageNet, model size should have extensive amout of parameters. The amount of parameters needed is larget than many neural network models for ImageNet. In such cases, classical regime of the U-shaped risk curve is more appropriate to understand generalization. For smaller datasets, simply training to obtain zero training risk often results in good test performance.</p>
<h2 id="decision-trees-and-ensemble-methods">Decision trees and ensemble methods<a class="headerlink" href="#decision-trees-and-ensemble-methods" title="Permanent link">&para;</a></h2>
<p>They experimented with random forest. To further enlarge the function class, they also considered ensembles of several interpolating trees. As a result, double descent curve appear just as with neural networks.</p>
<h2 id="concluding-thoughts">Concluding thoughts<a class="headerlink" href="#concluding-thoughts" title="Permanent link">&para;</a></h2>
<p>For random Fourier or random ReLU features, solutions are constructed explicitly by minimum norm linear regression in the feature space. For neural networks, we used SGD. SGD initialized at zero converges to minimum norm solution. While SGD for more general case is not fully understood, there is some evidence that similar minimum norm inductive bias is present. Ensembling in decision tree leads to interpolating solution with higher degree of smoothness, and those averaged solution performed better than any individual tree. So all three methods lead to minimum norm solution. </p>
<p>In this paper, modern models usually outperform the classical model on the test set. But beside that, there is a growing understanding that larger models are easy to optimize as local methods, such as SGD, converge to global minima of the training risk in over parametrized regimes. Thus, large interpolting models have low test risk and easy to optimize at the same time. It is likely that the models to the left of the interpolation peak have optimzation properties qualitatively different from those to the right.</p>
<p>The understanding of model performance developed in this work delineates the limits of classical analyses and opens new lines of enquiry to study and compare computational, statistical, and mathematical properties of the classical and modern regimes in machine learning.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["content.code.copy"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>