# Trustworthy AI: From Principles to Practices

I am reading this survey to overview what kind of research is going on on field of trustworthy AI. 

## Introduction

AI practitioners traditionally considered system performance to be the main metric in their workflows. But other kinds of aspect should also be considered to improve trustworthiness, such as robustness, algorithmic fairness, explainability, and transparency. Those aspects should be consider throughout the while lifecycle of an AI system, and those aspect may interfere with each other. 


## Aspects beyond predictive accuracy 
### Robustness
AI can be vulnerable at the level of data, algorithms, and systems, respectively. If AI model is trained without considering the diverse distributions of data in different secenarios, its performance will be significantly affected. The robustness against distributional shift has been a common problem. For example, in the field of autonomous driving, industry are working hard to enhance the performance of vehicles in nightime or rainy scenes to guarantee the system's reliability. 

Adversarial attack and defenses against it have raised concerns in both academia and the industry in recent years. Some study cateraorized adversarial attack with respect to the attack timing. Decision time attack perturbs the input samples, training time attack injects carefully desinged samples into training data. There are other type of attacks such as feature space attacks, problem space attacks, and model stealing.

System level robustness against illegal inputs should also be considered. For example, lidar perceptron system for autonomous vehicle might perceive laser beams emitted by lidars in other vehicles.

Proper test is needed to evaluate and enhance to robustness of AI. Threre are functional test and performance test. From the attackers's perspective, the rate of success of an attack intuitively measures the robustness of the system.

We may also consider certified verification of the adversarial robustness of an AI model. For example, we may derive lower bound of the minimum distortion to an attack on an AI model.

### Generalization 
Generalization is she capability to make accurate predictions regarding unseen data. Generalization has an impact on AI trustworthiness. AI should make predictions on realistic data, even on domains or distributions which they are not trained, so generalization affects the reliability and risk of practical systems. Also, AI models should be able to generlaize without exhaustively collect and annotate large amounts of data for various domains, so deployment of AI system can be more affordable and sustainable.

Generalization is closely related to robustness. An algorithm that is robust agains small perturbations has better generalization, but robustness agains different data distributions may hurt the model's generalization.

To evaluate generalization, past ML studies have developed rich approaches to measure the bounds of models' generalization error, such as Rademacher complexity and Vapnik-Chervonenkis dimension. Deep Neural Network (DNN) has property that it obtains generalization despite their massive capcity, that has been examined by the perspective of bias-variance tradeoff.

### Explainability and Transparency
There is a demand for AI service users for the right to know the intention, business model, and technological mechanism of AI products.

Explainability is understanding how an AI model makes its decision. From the perspective of scientific research, we need understanding about how data, parameters, precedures, and outcomes of AI. From persepective of building AI models, we need explainability to better use AI. 

Some studies tries to design explainable model. There are series of fully or partially explainable ML models. However, some complex models like DNN have exhibited better performance, it can't be explained by their design. Researcheres does post hoc explanation, that addresses model's behavior by analyzing its input, intermediate result, and output. 

Since there is ambiguity of the psychological outlining of explainability, unified evaluation of explainability has been recognized as a challenge. There are some approaches such as subjective human evaluation and human-Ai task performacne.  Despite these evaluations, direct quantitative measurement of explainability remains a problem. 

Transparency considers Ai as a software system, and seeks to disclose information regarding its entire lifecycle. Transparency serves as basic requirement to build public's trust in AI systems.

To make AI system transparent, variety of information regarding to its creation should be sisclosed. The recent trend of open source systems significantly contributes to the algorithmic transparency. Transparency of the runtime process and decision making should also be considered in various scenarios. Qualitative evaluation of transparency has undergone recent advances in the AI industry. 

### Reproducibility 

Reproducibility enables effective verificaiton of research, and allows the community to quickly convert the lasest approaches into practice or conduct follow-up research. 

### Fairness

It is important for practitioners to keep that the fairness of AI systems in mind to avoid instilling or exacerbating social bias.

Common objective of fairness is to mitigate the effects of biases. Bias often manifest in the form of unfair treatment of different groups of people based on their protected inforation. 

Fairness can be applicable at multiple granularities of system behavior. At each granularity, we concern fairness of outcome and fairness of process. In tasks like face identification, we concern the aggregated behavior and the bias among different groups. In task like resume reviewing for candidate screening, where   sensitive variable can be easility decoupled from the other features that determine the system's prediction, we consider bias among individuals.

In the group level, there can be different types of fairness. Independence requires system to be statistically independent of sensetive variables. Seperation requires that independence principle hold conditioned on the unerlying ground truth. Sufficiency true outcome and sensitive variable to be independent. These principles are mutually exclusive under certain circumstances.

Metrices of fairness can differ according to the properties of model and tasks. This can depend on 
- whether task output, sensitive variables, model prediction are discrete or continuous
- whether there is enough empirical data
- number of sensitive variables we have 


### Privacy protection
Privacy protection refers to protecting against unauthorized use of the data that can directly or indirectly identify a person or household. There are techniques to protect the privacy in data collection and processing, model training, and model deployment. There are various mathematical methods to formally verify the protectiveness of privacy-preserving approaches. 


## Systematic approach for trustworthy AI

Lifecycle of development of typical AI product can be partitioned into data preparation, algorithm design, development, deployment, and management. There are techniques for building trustworthy AI products for each lifecycle.

### Data preparation

During data collection, we should consider bias mitigation, explanation collection, and data provenance.

Bias mitigation techniques during data collection can be divided into two categories, debias sampling and debias annotation.  When sampling data points to annotate, we should note that dataset reflecting the user population does not guarantee fiarness, since statistical methods and metrics might favor majority groups. Choosing appropriate annotater is more crucial for underrepresented data, since annotation can be more biased on minority group. 

Adding explanation task to AI model can help explain the intermediate fearures of th emodel. This strategy is used in tasks like NLP-based reading comprehension by generating supporting sentences. 

We should record data lineage, including source, dependencies, contexts and steps of processing to get data provenance. Data proenance can enhance transparency, reproducibility, and accountability of an AI system. 

### Data preprocessing

Data processing helps removing inconsistent pollution of data. During data preprocessing, we should consider anomaly detection, data anonymization, and differential privacy.

Anomaly detection (or outlier detection) has been shown to be useful in addressing some requirements of AI trustworthiness. By anomaly detection, we can defend agains evasion attacks or data poisoning attacks. 

Data anonymization modifies the data so that protected private information cannot be recovered. There are various ways of anonymization for various types of data. Desirable data anonymization is expected to be immune from data de-anonymization or reidentification attacks.

Differential privacy shares information of groups within datasets while withholding individual samples. For example, $\epsilon$-differential privacy measures the extent to which statistical function on dataset reflects whethere an element has been removed. Enterprises like Apple have used DP to transform user data into a form from which the true data cannot be reproduced. 

## Algorithm design

### Robustness

Adversarial training is augmenting the training data with adversarial samples provies an intuitive approach for defense against adversarial attacks. Conventional adversarial training aguments data with respect to specific attacks, and there are various studies to improve this defsne by improving robustness of the model agains multiple types of attacks

Adversarial training might put regularization term to implicitly represent adversarial samples. Adversarial regularization prevent the outcome of the network from changing dramatically in the case of small input perturbations.

Certified robustness tries to formally verify the robustness of models. Those research usually focus on robustness near given training data, but global robustness has recently getting studied.



