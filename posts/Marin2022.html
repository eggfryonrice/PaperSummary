<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="/assets/css/style.css">
  <script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']]
  }
};
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" defer></script>

  <title>Uncovering structural diversity in commuting networks: Global and local entropy.</title>
</head>
<body>
  <main class="container">
    <p><a href="/">‚Üê Back to Home</a></p>
    
      <h1>Uncovering structural diversity in commuting networks: Global and local entropy.</h1>
    
    <h2 id="introduction">Introduction</h2>

<p>Diverse mobility patterns makes space for adaptation and innovation to maintain the functionaing of the system across different conditions and change. Entropy is one of th emost common ways of quantifying diversity. A common way to measure entropy in graphs in based on the degree distribution, measuring the probability of having a node witha  certain number of links. More recent studies extends information thoery concepts to network to understand entropy in weighted and directed graphs. In commuting networks, entropy is commonly used as a relative measure of the distribution of commuters amongst employmnet locations. Prior studies calculated entropy for individual trajectories or specific nodes within the network, i.e. at a local level. This paper test different measures of entropy at both global and local sale, considering the probability of distribution of flows in both nodes and links.</p>

<h2 id="methods">Methods</h2>

<p>In this paper, entropy is measured on uncertanty of origin and destination. They used different toy models of commuting networks to compare different measures (with different forms of normalisation) on both local and global scale applied to the links and nodes of the network. These measures consider commuting flows as directed and weighted graphs $G$, represented by set of $n$ vertices V(G) and $m$ edges E(G), and weight $w_{ij}$ is assigned to each edge to represent total flow from origin $i$ to destination $j$.</p>

<h2 id="global-diversity">Global diversity</h2>

<h3 id="spatial-distributiono-flabour-supply-and-demand">Spatial distributiono flabour supply and demand</h3>

<p>Labour supply and demand are not evely distributed in the geographic space, giving rise to complex patterns of spatial interactions. Entropy measure can explore whether flows in the city tend to be concentraed in dominant areas (monocentric pattern), or evenly dispersed from many origins to many destintaions (polycentric patterns).</p>

<p>With $p_{ij} = \frac{w_{ij}}{\sum_i \sum_j w_{ij}}$ representing probability of trip from node $i$ to node $j$, we can obtain the diversity of locations from/to which workers go/arrive to work by following global entropy measures:</p>
<ul>
  <li>Global out-flow entropy at node level:</li>
</ul>

\[H^{out}_{GN} = - \sum_{\forall i} \left(\sum_{\forall j} p_{ij}\right) log\left(\sum_{\forall j} p_{ij}\right)\]

<ul>
  <li>Global in-flow entropy at node level:</li>
</ul>

\[H^{in}_{GN} = - \sum_{\forall j} \left(\sum_{\forall i} p_{ij}\right) log\left(\sum_{\forall i} p_{ij}\right)\]

<p>In general, commuting destinations tend to be more highly concentrated than the commuting origins, since employment opportunities tends to cluster in few locations. But this does not always holds.</p>

<p>To normalize the result, we get the maximum possible value for each system, which is $H_{Tot} = \log n$. We can get normalized entropies by dividing entropies by $H_{Tot}$.</p>

<h3 id="commuter-trips-distribution">Commuter trips distribution</h3>

<p>The system will be more diverse if there are many combinations of origin-destination pairs, and amout of those pairs is evenly distributed. Global entropy at link level can be defined as:</p>

\[H_{GL} = - \sum_{\forall i} \sum_{\forall j} p_{ij} log p_{ij}\]

<p>Its maximum possible value is $H_{Tot} = \log m$, so we can get normalized entropy by dividing entropy by $H_{Tot}$. More sutable normalization can be obtained by considering maximum possible number o flinks in the graph, which is $n(n-1)$. In this case, we may divide $H_{max}$ instead of $H_{Tot}$.</p>

<h2 id="local-diversity">Local diversity</h2>

<p>We might also be interested in role of individual locations. They introduced local entropy at in and out commuting scenarios at node $i$:</p>
<ul>
  <li>Local in-flow entropy:</li>
</ul>

\[H_L^{in} = - \sum_{\forall j} \frac{w_{ji}}{\sum_k w_{ki}} log \frac{w_{ji}}{\sum_k w_{ki}}\]

<ul>
  <li>Local out-flow entropy:</li>
</ul>

\[H_L^{in} = - \sum_{\forall j} \frac{w_{ij}}{\sum_k w_{ik}} log \frac{w_{ij}}{\sum_k w_{ik}}\]

<p>Those measure give infomration about the node diversity in therms of the flows that are sent or received by its direct neighbors. Normalisation can be achieved by dividing maximum entropy given by in or out degree of the node, which are $\log(deg_{in}(v_i))$ or $\log(deg_{out}(v_i))$. Or maximum possible value, $\log (n-1)$ may be used.</p>

<p>They also described conditional entropy among all nodes.</p>

<ul>
  <li>Average local in-flow entropy:</li>
</ul>

\[H^{in}_{L\mu} = \sum_{\forall i} p_i (H_L^{in})_i\]

<ul>
  <li>Average local out-flow entropy:</li>
</ul>

\[H^{out}_{L\mu} = \sum_{\forall i} p_i (H_L^{out})_i\]

  </main>
</body>
</html>
