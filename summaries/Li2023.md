# Trustworthy AI: From Principles to Practices

I am reading this survey to overview what kind of research is going on on field of trustworthy AI. 

## Introduction

AI practitioners traditionally considered system performance to be the main metric in their workflows. But other kinds of aspect should also be considered to improve trustworthiness, such as robustness, algorithmic fairness, explainability, and transparency. Those aspects should be consider throughout the while lifecycle of an AI system, and those aspect may interfere with each other. 


## Aspects beyond predictive accuracy 
### Robustness
AI can be vulnerable at the level of data, algorithms, and systems, respectively. 
If AI model is trained without considering the diverse distributions of data in different secenarios, its performance will  e significantly affected. The robustness against distributional shift has been a common problem. For example, in the field of autonomous driving, industry are working hard to enhance the performance of vehicles in nightime or rainy scenes to guarantee the system's reliability. 

Adversarial attack and defenses against it have raised concerns in both academia and the industry in recent years. Some study cateraorized adversarial attack with respect to the attack timing. Decision time attack perturbs the input samples, training time attack injects carefully desinged samples into training data. There are other type of attacks such as feature space attacks, problem space attacks, and model stealing.

System level robustness against illegal inputs should alsobe considered. For example, lidar perceptron system for autonomous vehicle might perceive laser beams emitted by lidars in other vehicles.

Proper test is needed to evaluate and enhance to robustness of AI. Threre are functional test and performance test. From the attackers's perspective, the rate of success of an attack intuitively measures the robustness of the system.

We may also consider certified verification of the adversarial robustness of an AI model. For example, we may derive lower bound of the inimum distortion to an attack on an AI model.

### Generalization 
Genearalization is she capability to make accurate predictions regarding unseen data. Generalization has an impact on AI trustworthiness. AI should make predictions on realistic data, even on domains or distributions which they are not trained, so generalization affects the reliability and risk of practical systems. Also, AI models should be able to generlaize without exhaustively collect and annotate large amounts of data for various domains, so deployment of AI system can be more affordable and sustainable.

Generalization is closely related to robustness. An algorithm that is robust agains small perturbations has better generalization, but robustness agains different data distributions may hurt the model's generalization.

To evaluate genearlization, past ML studies have developed rich approaches to measure the bounds of models' generalization error, such as Rademacher complexity and Vapnik-Chervonenkis dimension. Deep Neural Network (DNN) has property that it obtains generalization despite their massive capcity, that has been examined by the perspective of bias-variance tradeoff.

### Explainability and Transparency
There is a demand for AI service users for the right to know the intention, business model, and technological mechanism of AI products.

Explainability is understanding how an AI model makes its decision. From the perspective of scientific research, we need understanding about how data, parameters, precedures, and outcomes of AI. From persepective of building AI models, we need explainability to better use AI. 

Some studies tries to design explainable model. There are series of fully or partially explainable ML models. However, some complex models like DNN have exhibited better performance, it can't be explained by their design. Researcheres does post hoc explanation, that addresses model's behavior by analyzing its input, intermediate result, and output. 

Since there is ambiguity of the psychological outlining of explainability, unified evaluation of explainability has been recognized as a challenge. There are some approaches such as subjective human evaluation and human-Ai task performacne.  Despite these evaluations, directy quantitative measurement of explainability remains a problem. 

Transparency considers Ai as a software system, and seeks to disclose information regarding it sentire lifecycle. Transparency serves as basic requirement to build public's trust in Ai systems.

To make AI system transparent, variety of information regarding to its creation should be sisclosed. The recent trend of open source systems significantly contributes to the algorithmic transparency. Transparency of the runtime process and decision making should also be considered in various scenarios. Qualitative evaluation of transparency has undergone recent advances in the AI industry. 

### Reproducibility 

Reproducibility enables effective verificaiton of research, and allos the community to quickly convert the lastest approaches into practice or conduct follow-up research. 

### Fairness

It is important for practitioners to keep that the fairness of AI systems in mind to avoid instilling or exacerbating social bias.

Common objective of fairness is to mitigate the effects of biases. Bias often manifest in the form of unfair treatment of different groups of people based on their protected inforation. 

Fairness can be applicable at multiple granularities of system behavior. At each granularity, we concern fairness of outcome and fairness of process. In tasks like face identification, we concern the aggregated behavior and the bias among different groups. In task like resume reviewing for candidate screening, wheresensitive variable can be easility decoupled from the other features that determine the system's prediction, we consider bias among individuals.

In the group evel, there can be different types of fairness. Independence requires system to be statistically independent of sensetive variables. Seperation requires that independence principle hold conditioned on the unerlying ground truth. Sufficiency true outcome and sensitive variable to be independent. These principles are mutually exclusive under certain circumstances.

Metrices of fairness can differ according to the properties of model and tasks. This can depend on 
- whether task output, sensitive variables, model prediction are discrete or continuous
- whether there is enough empirical data
- number of sensitive variables we have 


### Privacy protection
Privacy protection refers to protecting against unauthorized use of the data that can directly or indirectly identify a person or household. There are techniques to protect the privacy in data collection and processing, model training, and model deployment. There are various mathematical methods to formally verify the protectiveness of privacy-preserving approaches. 


## Systematic approach for trustworthy AI







